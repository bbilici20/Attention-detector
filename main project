# -*- coding: utf-8 -*-
"""
Created on Mon Jul 18 23:45:33 2022

@author: beril
"""


import numpy as np
import cv2
import mediapipe as mp
from keras.models import model_from_json

frame_counter = 0

mp_drawing = mp.solutions.drawing_utils
drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)
mp_drawing_styles = mp.solutions.drawing_styles
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(
    max_num_faces = 40,
    refine_landmarks = True,
    min_detection_confidence = 0.2,
    min_tracking_confidence = 0.5)

emotion_dict = {0 :"happy", 1: "neutral", 2: "sad", 3: "surprise"}
emotion_index = 0

json_file = open("model_architecture\\emotion_model.json")
json_file_readed = json_file.read()
model = model_from_json(json_file_readed)
model.load_weights("model_weights\\saved_model")

cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_POS_MSEC,1248000)

#this is the part I was responsible for
while cap.isOpened():
    success, image = cap.read()
    if success:
        #image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)
        #image.flags.writeable = False
        
        results = face_mesh.process(image)
        
        #image.flags.writeable = True
        
        grayimage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        #image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        
        img_h, img_w = grayimage.shape
        
        
        if results.multi_face_landmarks:
            for face_landmarks in results.multi_face_landmarks:
                face_2d = []
                yawn = []
                position = []
                for idx, lm in enumerate(face_landmarks.landmark):
                    if idx == 10 or idx == 152 or idx == 234 or idx==454:
                        x, y = int(lm.x * img_w), int(lm.y * img_h)

                        # Get the 2D Coordinates
                        face_2d.append([x, y])
                        
                        
                    if idx == 50 or idx == 93 or idx == 280 or idx == 323 or idx == 10 or idx == 298 or idx == 284 or idx == 288 or idx == 435:
                        x, y = int(lm.x * img_w), int(lm.y * img_h)

                        # Get the 2D Coordinates
                        position.append([x, y])
                    if idx == 13 or idx == 14 or idx == 1:
                        x, y = int(lm.x * img_w), int(lm.y * img_h)

                        # Get the 2D Coordinates
                        yawn.append([x, y])
                    

                
                if position[1][0]<position[2][0]:
                    text = "Looking Left"
                elif position[7][0]<position[3][0]:
                    text = "Looking Right"
                elif position[6][1]<position[4][1]:
                    text = "Looking Up"
                elif position[5][1]<position[8][1]:
                    text = "Looking Down" 
                else:
                    text = "Forward"
                    
                cv2.putText(image, text, (face_2d[0][0]+10, face_2d[0][1]+10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        
                if (yawn[0][1]-yawn[1][1])>(yawn[1][1]-yawn[2][1]):
                    text2 = "Yawning"
                
                else:
                    text2 = "Not yawning"
                    
                cv2.putText(image, text2, (yawn[0][0]+10, yawn[0][1]+10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                    
                try:
                    cv2.rectangle(image, (face_2d[2][0]-50,face_2d[0][1]-50 ), (face_2d[3][0]+30,face_2d[1][1]+20), (255, 0, 0), 2)   
                    #height = face_2d[1][1]-face_2d[0][1]+50
                    #width = face_2d[3][0]-face_2d[2][0]+40
                    #ekle = (height-width)/2
                    crop_img = grayimage[face_2d[0][1]-50:face_2d[1][1]+20, face_2d[2][0]-50:face_2d[3][0]+30]
                    resized_img = np.expand_dims(np.expand_dims(cv2.resize(crop_img, (48, 48)), -1), 0)
                    resized_img /= 255
                    
                #end of my part

                except Exception as e:
                    pass
                if (frame_counter %50 == 0):    
                    predictions = model.predict(resized_img)
                    emotion_index = int(np.argmax(predictions))
                cv2.putText(image, emotion_dict[emotion_index], (face_2d[0][0]+40, face_2d[0][1]+40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)    
           
        
        image = cv2.resize(image, (1080, 720))
        cv2.imshow('Face Recognition', image)
        frame_counter += 1
        if cv2.waitKey(5) & 0xFF == 27:
            break
                
cap.release()                
cv2.destroyAllWindows()                
              
